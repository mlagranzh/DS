{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simpsons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOa8Om9jAyEt"
      },
      "source": [
        "\n",
        "## **Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI3e_7PKA0nC"
      },
      "source": [
        "# Путешествие по Спрингфилду.\n",
        "\n",
        "\n",
        "Сегодня вам предстоить помочь телекомпании FOX  в обработке их контента. Как вы знаете сериал Симсоны идет на телеэкранах более 25 лет и за это время скопилось очень много видео материала. Персоонажи менялись вместе с изменяющимися графическими технологиями   и Гомер 2018 не очень похож на Гомера 1989. Нашей задачей будет научиться классифицировать персонажей проживающих в Спрингфилде. Думаю, что нет смысла представлять каждого из них в отдельности.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rPdVwfZBnIL",
        "outputId": "5a11f150-9928-486e-a705-ec2b2efa364f"
      },
      "source": [
        "# Произведем необходимые установки\n",
        "!pip install torchvision\n",
        "!pip install catalyst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: catalyst in /usr/local/lib/python3.6/dist-packages (20.11)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.7.0+cu101)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n",
            "Requirement already satisfied: GitPython>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.1.11)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.1.4)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.18.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.41.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (20.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.2)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (3.7.4.3)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.1.1->catalyst) (4.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (50.3.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.6.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst) (3.12.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->catalyst) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.3.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.35.1)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.1->catalyst) (3.0.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.2.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (2.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pOeoDM3ANiN",
        "outputId": "c66f2060-dd21-4836-dc9d-aba3ea805069"
      },
      "source": [
        "# Проверим, включен ли графический процессор для этого ноутбука\n",
        "\n",
        "import torch\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgSMG1z8ASlY",
        "outputId": "337479e8-714a-4fcb-f9e8-1f494bad7bd5"
      },
      "source": [
        "# Импортируем данные из google drive\n",
        "# Импортируем данные из google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "!unzip -q /content/gdrive/My\\ Drive/train.zip -d train\n",
        "!unzip -q /content/gdrive/My\\ Drive/testset.zip -d test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "replace train/train/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHUZs76nAkU2"
      },
      "source": [
        "!nvidia-smi\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svczvPYyBjoS"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
        "# мы будем игнорировать warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGPsgIq2BrlI"
      },
      "source": [
        "# разные режимы датасета \n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения будут масштабированы к размеру 224x224 px\n",
        "RESCALE_SIZE = 224\n",
        "# работаем на видеокарте\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lddp2IPB23D"
      },
      "source": [
        "Ниже мы исспользуем враппер над датасетом для удобной работы.  \n",
        "\n",
        "ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n",
        "$input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n",
        "\n",
        "\n",
        "Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n",
        " Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqs4qYd4Bxv6"
      },
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет с картинками, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files, mode):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "\n",
        "        self.len_ = len(self.files)\n",
        "     \n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            self.labels = [path.parent.name for path in self.files]\n",
        "            self.label_encoder.fit(self.labels)\n",
        "\n",
        "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "                  pickle.dump(self.label_encoder, le_dump_file)\n",
        "                      \n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "      \n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
        "        ])\n",
        "        x = self.load_sample(self.files[index])\n",
        "        x = self._prepare_sample(x)\n",
        "        x = np.array(x / 255, dtype='float32')\n",
        "        x = transform(x)\n",
        "        if self.mode == 'test':\n",
        "            return x\n",
        "        else:\n",
        "            label = self.labels[index]\n",
        "            label_id = self.label_encoder.transform([label])\n",
        "            y = label_id.item()\n",
        "            return x, y\n",
        "        \n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA0OuVELCOk4"
      },
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    \"\"\"Imshow для тензоров\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9W-eoz1CS82"
      },
      "source": [
        "TRAIN_DIR = Path('train/train')\n",
        "TEST_DIR = Path('test/testset')\n",
        "\n",
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtU571o2CUS3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_labels = [path.parent.name for path in train_val_files]\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
        "                                          stratify=train_val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegxHXUxCVnV"
      },
      "source": [
        "val_dataset = SimpsonsDataset(val_files, mode='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHKCXfsHCvjY"
      },
      "source": [
        "Давайте посмотрим на наших героев внутри датасета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6kBRI9SCl9G"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc1ULDWiC8Nr"
      },
      "source": [
        "Используем сеть AlexNet, в которой изменим последний слой согласно требуемому количеству классов - 42. Обучим на 30 эпохах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjfkDJSeCxmU"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHg3kNChDCE7"
      },
      "source": [
        "model = models.alexnet(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1SAWQi4DHFB"
      },
      "source": [
        "# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n",
        "num_features = 4096\n",
        "# Заменяем Fully-Connected слой на наш линейный классификатор\n",
        "model.classifier[6] = nn.Linear(num_features, 42)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVJlrOcrDI0d"
      },
      "source": [
        "from catalyst import dl, metrics\n",
        "train_dataset = SimpsonsDataset(train_files, mode='train')\n",
        "val_dataset = SimpsonsDataset(train_files, mode='val')\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128)\n",
        "\n",
        "loaders = {\n",
        "    \"train\": train_dataloader,\n",
        "    \"valid\": val_dataloader\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmfEhfPZDLOp"
      },
      "source": [
        "class ImgRunner(dl.Runner):\n",
        "\n",
        "    def predict_batch(self, batch):\n",
        "        # model inference step\n",
        "        return self.model(batch[0].to(self.device).view(batch[0].size(0), -1))\n",
        "\n",
        "    def _handle_batch(self, batch):\n",
        "        # model train/valid step\n",
        "        x, y = batch\n",
        "        self.input = {\"targets\": y}\n",
        "        y_hat = self.model(x)\n",
        "        self.output = {\"logits\": y_hat}\n",
        "\n",
        "runner = ImgRunner()\n",
        "runner.train(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    callbacks=[\n",
        "        dl.CriterionCallback(),\n",
        "        dl.OptimizerCallback(), \n",
        "        dl.AccuracyCallback()\n",
        "    ],\n",
        "    loaders=loaders,\n",
        "    num_epochs=30,\n",
        "    verbose=True,\n",
        "    main_metric=\"accuracy01\",\n",
        "    minimize_metric=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbBqKXmPHAnM"
      },
      "source": [
        "Выполним предикт, результат запишем в csv файл."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uPeho2tDmd7"
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "    \n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFMy6ExwDtrU"
      },
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd-Ds4rMDdCS"
      },
      "source": [
        "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "\n",
        "probs = predict(model, test_loader)\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imN6yAYiDiY8"
      },
      "source": [
        "import pandas as pd\n",
        "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "my_submit.head()\n",
        "my_submit.to_csv('gdrive/My Drive/simple_cnn_baseline.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}